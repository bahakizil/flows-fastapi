# React Flow + Python FastAPI ile Flowise Benzeri Uygulama - BaÅŸtan Sona Rehber

## BÃ–LÃœM 1: TERÄ°MLERÄ° ANLAMAK

### 1.1 Node Nedir? Class mÄ±, Obje mi?

**Node = Lego ParÃ§asÄ±**

```python
# Node bir CLASS'tÄ±r (kalÄ±p/ÅŸablon)
class ChatGPTNode:
    def __init__(self):
        self.name = "ChatGPT"
        self.inputs = ["prompt", "temperature"]
        self.outputs = ["response"]
    
    def run(self, prompt, temperature):
        # ChatGPT'ye baÄŸlan ve cevap al
        return "AI response"

# Node'u kullanmak = OBJE oluÅŸturmak
node1 = ChatGPTNode()  # Bu bir OBJE (instance)
result = node1.run("Merhaba", 0.7)
```

### 1.2 Edge Nedir?

**Edge = BaÄŸlantÄ± Kablosu**

```python
# Frontend'den gelen JSON
edge = {
    "source": "node1",        # Nereden (hangi node'dan)
    "sourceHandle": "output", # O node'un hangi Ã§Ä±kÄ±ÅŸÄ±ndan
    "target": "node2",        # Nereye (hangi node'a)
    "targetHandle": "input"   # O node'un hangi giriÅŸine
}

# Yani: node1'in output'u â†’ node2'nin input'una baÄŸlÄ±
```

### 1.3 Objelerin Node'lara Input Olarak GeÃ§mesi

```python
# Node 1: ChatGPT objesi oluÅŸturur
class ChatGPTNode:
    def run(self):
        chatgpt = ChatGPT(api_key="xxx")  # Bir OBJE oluÅŸturdu
        return chatgpt  # Bu objeyi dÃ¶ndÃ¼rdÃ¼

# Node 2: Bu objeyi alÄ±r ve kullanÄ±r
class ConversationNode:
    def run(self, llm):  # llm = yukarÄ±daki chatgpt objesi
        response = llm.chat("Merhaba")  # Objeyi kullanÄ±yor
        return response

# BaÄŸlantÄ±:
node1_result = ChatGPTNode().run()      # chatgpt objesi
node2_result = ConversationNode().run(node1_result)  # objeyi aldÄ±
```

### 1.4 Directed Graph (YÃ¶nlÃ¼ Graf) Nedir?

```
Directed Graph = Tek yÃ¶nlÃ¼ yollar

A â†’ B â†’ C
â†“       â†“
D â†’ E â†’ F

- Ok yÃ¶nÃ¼nde gidebilirsin
- C'den A'ya gidemezsin (ters yÃ¶n yok)
```

### 1.5 Topological Sort Nedir?

**SÄ±ralama AlgoritmasÄ±: Hangi node'u Ã¶nce Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z?**

```python
# Problem:
# B, A'ya baÄŸlÄ±
# C, B'ye baÄŸlÄ±
# Hangi sÄ±rayla Ã§alÄ±ÅŸtÄ±rmalÄ±? A â†’ B â†’ C

def topological_sort(nodes, edges):
    # 1. Her node'un kaÃ§ baÄŸlantÄ±sÄ± var?
    dependencies = {
        "A": 0,  # Kimseye baÄŸlÄ± deÄŸil
        "B": 1,  # A'ya baÄŸlÄ±
        "C": 1   # B'ye baÄŸlÄ±
    }
    
    # 2. BaÄŸlÄ± olmayanlardan baÅŸla
    order = []
    while nodes:
        # BaÄŸÄ±mlÄ±lÄ±ÄŸÄ± olmayanÄ± bul
        for node in nodes:
            if dependencies[node] == 0:
                order.append(node)  # SÄ±raya ekle
                # Bu node'a baÄŸlÄ± olanlarÄ±n sayÄ±sÄ±nÄ± azalt
                
    return order  # ["A", "B", "C"]
```

### 1.6 End Node ve Geriye Traverse

```
End Node = Son durak (output edge'i yok)

A â†’ B â†’ C
    â†“
    D â†’ E (End node - E'den baÅŸka yere ok yok)

Geriye traverse = Sondan baÅŸa doÄŸru git
E â†’ D â†’ B â†’ A (dependencies'leri bul)
```

### 1.7 Handle Nedir?

```
Handle = Priz/Soket

[ChatGPT Node]
  Inputs:
    - prompt (handle)     â† Buraya prompt baÄŸlanÄ±r
    - temperature (handle) â† Buraya temperature baÄŸlanÄ±r
  Outputs:
    - response (handle)   â†’ Buradan response Ã§Ä±kar
```

### 1.8 ReAct Agent Nedir?

```
ReAct = Reason + Act (DÃ¼ÅŸÃ¼n + Hareket Et)

1. Soru: "Paris'in nÃ¼fusu nedir?"
2. DÃ¼ÅŸÃ¼n: "Bunu bilmiyorum, arama yapmam lazÄ±m"
3. Hareket: SearchTool.search("Paris population")
4. SonuÃ§: "2.1 milyon"
5. DÃ¼ÅŸÃ¼n: "CevabÄ± buldum"
6. Final: "Paris'in nÃ¼fusu 2.1 milyondur"
```

### 1.9 State Management

```python
# State = HafÄ±za/Durum

flow_state = {
    "user_name": "Ahmet",
    "conversation_id": "123",
    "messages": ["Merhaba", "NasÄ±lsÄ±n?"],
    "custom_data": {"mood": "happy"}
}

# State'e yazma
flow_state["user_name"] = "Mehmet"

# State'den okuma
name = flow_state["user_name"]
```

### 1.10 Node Registry

```python
# Registry = Telefon Rehberi

node_registry = {
    "chatgpt": ChatGPTNode,      # Ä°sim â†’ Class eÅŸleÅŸmesi
    "prompt": PromptNode,
    "memory": MemoryNode
}

# KullanÄ±m
node_name = "chatgpt"
NodeClass = node_registry[node_name]  # Class'Ä± bul
node = NodeClass()  # Obje oluÅŸtur
```

## BÃ–LÃœM 2: SIFIRDAN UYGULAMA YAPIMI

### ADIM 1: Proje YapÄ±sÄ±

```
my-flowise-clone/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI ana dosya
â”‚   â”œâ”€â”€ models.py             # Pydantic modeller
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py          # Base node class
â”‚   â”‚   â”œâ”€â”€ llm_nodes.py     # LLM node'larÄ±
â”‚   â”‚   â”œâ”€â”€ tool_nodes.py    # Tool node'larÄ±
â”‚   â”‚   â””â”€â”€ chain_nodes.py   # Chain node'larÄ±
â”‚   â”œâ”€â”€ executor.py          # Flow Ã§alÄ±ÅŸtÄ±rÄ±cÄ±
â”‚   â””â”€â”€ registry.py          # Node registry
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.js
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ Flow.js      # React Flow component
    â”‚   â”‚   â””â”€â”€ Sidebar.js   # Node listesi
    â”‚   â””â”€â”€ api.js           # Backend iletiÅŸimi
```

### ADIM 2: Backend - Base Node Sistemi

```python
# backend/nodes/base.py
from abc import ABC, abstractmethod
from typing import Any, Dict, List
from pydantic import BaseModel

# Node'un aldÄ±ÄŸÄ± parametreler
class NodeInput(BaseModel):
    name: str          # "prompt", "temperature" gibi
    type: str          # "string", "number", "object"
    required: bool = True
    default: Any = None

# Node'un Ã§Ä±ktÄ±larÄ±
class NodeOutput(BaseModel):
    name: str          # "response", "result" gibi
    type: str          # Ã‡Ä±ktÄ±nÄ±n tipi

# Ana Node sÄ±nÄ±fÄ± (kalÄ±p)
class BaseNode(ABC):
    """TÃ¼m node'larÄ±n tÃ¼reyeceÄŸi ana sÄ±nÄ±f"""
    
    def __init__(self):
        self.id = ""  # Her node'un unique ID'si
        self.name = ""  # Node tipi (chatgpt, prompt, vb)
        self.label = ""  # UI'da gÃ¶rÃ¼nen isim
        self.category = ""  # Kategori (llms, tools, vb)
        self.inputs: List[NodeInput] = []
        self.outputs: List[NodeOutput] = []
        
    @abstractmethod
    async def execute(self, inputs: Dict[str, Any]) -> Any:
        """Node'u Ã§alÄ±ÅŸtÄ±r - Alt sÄ±nÄ±flar implement etmeli"""
        pass
    
    def validate_inputs(self, inputs: Dict[str, Any]) -> bool:
        """Gelen inputlarÄ± kontrol et"""
        for input_def in self.inputs:
            if input_def.required and input_def.name not in inputs:
                raise ValueError(f"Required input missing: {input_def.name}")
        return True
```

### ADIM 3: Ä°lk Node'umuzu YapalÄ±m - ChatGPT Node

```python
# backend/nodes/llm_nodes.py
from .base import BaseNode, NodeInput, NodeOutput
from langchain_openai import ChatOpenAI

class ChatGPTNode(BaseNode):
    """ChatGPT/OpenAI modeli node'u"""
    
    def __init__(self):
        super().__init__()
        self.name = "chatgpt"
        self.label = "ChatGPT"
        self.category = "llms"
        
        # Bu node'un inputlarÄ±
        self.inputs = [
            NodeInput(name="api_key", type="string", required=True),
            NodeInput(name="model", type="string", default="gpt-3.5-turbo"),
            NodeInput(name="temperature", type="number", default=0.7)
        ]
        
        # Bu node'un outputlarÄ±
        self.outputs = [
            NodeOutput(name="llm", type="ChatOpenAI")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> ChatOpenAI:
        """ChatGPT objesi oluÅŸtur ve dÃ¶ndÃ¼r"""
        # Input'larÄ± al
        api_key = inputs["api_key"]
        model = inputs.get("model", "gpt-3.5-turbo")
        temperature = inputs.get("temperature", 0.7)
        
        # LangChain ChatOpenAI objesi oluÅŸtur
        llm = ChatOpenAI(
            api_key=api_key,
            model=model,
            temperature=temperature
        )
        
        return llm  # Bu obje baÅŸka node'lara input olacak
```

### ADIM 4: Prompt Template Node

```python
# backend/nodes/llm_nodes.py (devamÄ±)
from langchain.prompts import PromptTemplate

class PromptTemplateNode(BaseNode):
    """Prompt ÅŸablonu node'u"""
    
    def __init__(self):
        super().__init__()
        self.name = "prompt_template"
        self.label = "Prompt Template"
        self.category = "prompts"
        
        self.inputs = [
            NodeInput(name="template", type="string", required=True),
            NodeInput(name="input_variables", type="list", default=["input"])
        ]
        
        self.outputs = [
            NodeOutput(name="prompt", type="PromptTemplate")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> PromptTemplate:
        """Prompt template oluÅŸtur"""
        template = inputs["template"]
        input_variables = inputs.get("input_variables", ["input"])
        
        prompt = PromptTemplate(
            template=template,
            input_variables=input_variables
        )
        
        return prompt
```

### ADIM 5: Chain Node - ParÃ§alarÄ± BirleÅŸtir

```python
# backend/nodes/chain_nodes.py
from langchain.chains import LLMChain
from .base import BaseNode, NodeInput, NodeOutput

class LLMChainNode(BaseNode):
    """LLM ve Prompt'u birleÅŸtiren chain"""
    
    def __init__(self):
        super().__init__()
        self.name = "llm_chain"
        self.label = "LLM Chain"
        self.category = "chains"
        
        self.inputs = [
            NodeInput(name="llm", type="object", required=True),
            NodeInput(name="prompt", type="object", required=True)
        ]
        
        self.outputs = [
            NodeOutput(name="chain", type="LLMChain")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> LLMChain:
        """LLM ve Prompt'u birleÅŸtir"""
        llm = inputs["llm"]  # ChatGPTNode'dan gelen obje
        prompt = inputs["prompt"]  # PromptTemplateNode'dan gelen obje
        
        chain = LLMChain(
            llm=llm,
            prompt=prompt
        )
        
        return chain
```

### ADIM 6: Node Registry - Node'larÄ± Kaydet

```python
# backend/registry.py
from typing import Dict, Type
from nodes.base import BaseNode
from nodes.llm_nodes import ChatGPTNode, PromptTemplateNode
from nodes.chain_nodes import LLMChainNode

class NodeRegistry:
    """TÃ¼m node'larÄ± tutan registry (telefon rehberi gibi)"""
    
    def __init__(self):
        self.nodes: Dict[str, Type[BaseNode]] = {}
        self._register_all_nodes()
    
    def _register_all_nodes(self):
        """TÃ¼m node'larÄ± kaydet"""
        # Her node'u ismiyle kaydet
        node_classes = [
            ChatGPTNode,
            PromptTemplateNode,
            LLMChainNode
        ]
        
        for NodeClass in node_classes:
            instance = NodeClass()
            self.nodes[instance.name] = NodeClass
    
    def get_node_class(self, node_name: str) -> Type[BaseNode]:
        """Ä°sme gÃ¶re node class'Ä±nÄ± getir"""
        if node_name not in self.nodes:
            raise ValueError(f"Unknown node: {node_name}")
        return self.nodes[node_name]
    
    def create_node(self, node_name: str) -> BaseNode:
        """Yeni node instance'Ä± oluÅŸtur"""
        NodeClass = self.get_node_class(node_name)
        return NodeClass()
    
    def get_all_nodes(self) -> Dict[str, Dict]:
        """Frontend iÃ§in tÃ¼m node bilgilerini getir"""
        result = {}
        for node_name, NodeClass in self.nodes.items():
            instance = NodeClass()
            result[node_name] = {
                "name": instance.name,
                "label": instance.label,
                "category": instance.category,
                "inputs": [inp.dict() for inp in instance.inputs],
                "outputs": [out.dict() for out in instance.outputs]
            }
        return result
```

### ADIM 7: Flow Executor - AkÄ±ÅŸÄ± Ã‡alÄ±ÅŸtÄ±r

```python
# backend/executor.py
from typing import Dict, List, Any
from collections import defaultdict, deque
from registry import NodeRegistry

class FlowExecutor:
    """Flow'u Ã§alÄ±ÅŸtÄ±ran motor"""
    
    def __init__(self, registry: NodeRegistry):
        self.registry = registry
        self.node_outputs = {}  # Her node'un Ã§Ä±ktÄ±sÄ±nÄ± sakla
    
    async def execute(self, flow_data: Dict) -> Any:
        """
        Flow'u Ã§alÄ±ÅŸtÄ±r
        flow_data = {
            "nodes": [...],  # Node listesi
            "edges": [...]   # BaÄŸlantÄ± listesi
        }
        """
        nodes = flow_data["nodes"]
        edges = flow_data["edges"]
        
        # 1. Ã‡alÄ±ÅŸtÄ±rma sÄ±rasÄ±nÄ± bul (topological sort)
        execution_order = self._get_execution_order(nodes, edges)
        
        # 2. Her node'u sÄ±rayla Ã§alÄ±ÅŸtÄ±r
        for node_id in execution_order:
            # Node bilgisini bul
            node_data = next(n for n in nodes if n["id"] == node_id)
            
            # Node instance'Ä± oluÅŸtur
            node = self.registry.create_node(node_data["type"])
            node.id = node_id
            
            # Bu node'un input'larÄ±nÄ± hazÄ±rla
            node_inputs = await self._prepare_inputs(node_id, node_data, edges)
            
            # Node'u Ã§alÄ±ÅŸtÄ±r
            result = await node.execute(node_inputs)
            
            # Sonucu sakla
            self.node_outputs[node_id] = result
        
        # Son node'un Ã§Ä±ktÄ±sÄ±nÄ± dÃ¶ndÃ¼r
        return self.node_outputs[execution_order[-1]]
    
    def _get_execution_order(self, nodes: List[Dict], edges: List[Dict]) -> List[str]:
        """Topological sort ile Ã§alÄ±ÅŸtÄ±rma sÄ±rasÄ±nÄ± bul"""
        # Her node'un kaÃ§ giriÅŸ baÄŸlantÄ±sÄ± var?
        in_degree = defaultdict(int)
        adjacency = defaultdict(list)
        
        # TÃ¼m node'larÄ± ekle
        node_ids = [n["id"] for n in nodes]
        for node_id in node_ids:
            in_degree[node_id] = 0
        
        # BaÄŸlantÄ±larÄ± say
        for edge in edges:
            source = edge["source"]
            target = edge["target"]
            adjacency[source].append(target)
            in_degree[target] += 1
        
        # GiriÅŸ baÄŸlantÄ±sÄ± olmayanlardan baÅŸla
        queue = deque([n for n in node_ids if in_degree[n] == 0])
        result = []
        
        while queue:
            node = queue.popleft()
            result.append(node)
            
            # Bu node'a baÄŸlÄ± olanlarÄ±n giriÅŸ sayÄ±sÄ±nÄ± azalt
            for neighbor in adjacency[node]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        return result
    
    async def _prepare_inputs(self, node_id: str, node_data: Dict, edges: List[Dict]) -> Dict:
        """Node iÃ§in input'larÄ± hazÄ±rla"""
        inputs = {}
        
        # Node'un kendi input deÄŸerleri (UI'dan gelen)
        if "inputs" in node_data["data"]:
            inputs.update(node_data["data"]["inputs"])
        
        # BaÄŸlantÄ±lardan gelen input'lar
        incoming_edges = [e for e in edges if e["target"] == node_id]
        
        for edge in incoming_edges:
            source_id = edge["source"]
            target_handle = edge["targetHandle"]
            
            # Source node'un output'unu al
            if source_id in self.node_outputs:
                inputs[target_handle] = self.node_outputs[source_id]
        
        return inputs
```

### ADIM 8: FastAPI Ana Dosya

```python
# backend/main.py
from fastapi import FastAPI, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Any
import json

from registry import NodeRegistry
from executor import FlowExecutor

app = FastAPI()

# CORS ayarlarÄ± (React'tan gelen isteklere izin ver)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global registry
registry = NodeRegistry()

# API Modelleri
class FlowData(BaseModel):
    nodes: list
    edges: list

class ChatMessage(BaseModel):
    message: str
    flow_id: str

# API Endpoints
@app.get("/api/nodes")
async def get_nodes():
    """TÃ¼m mevcut node'larÄ± getir"""
    return registry.get_all_nodes()

@app.post("/api/execute")
async def execute_flow(flow_data: FlowData):
    """Flow'u Ã§alÄ±ÅŸtÄ±r"""
    executor = FlowExecutor(registry)
    result = await executor.execute(flow_data.dict())
    return {"result": str(result)}

@app.websocket("/ws/chat/{flow_id}")
async def websocket_chat(websocket: WebSocket, flow_id: str):
    """WebSocket Ã¼zerinden chat"""
    await websocket.accept()
    
    try:
        while True:
            # MesajÄ± al
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # Flow'u Ã§alÄ±ÅŸtÄ±r
            # TODO: Flow'u veritabanÄ±ndan al
            # TODO: MesajÄ± flow'a input olarak ver
            
            # CevabÄ± gÃ¶nder
            await websocket.send_json({
                "type": "response",
                "message": "AI response here"
            })
            
    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "message": str(e)
        })

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### ADIM 9: Frontend - React Flow Kurulumu

```bash
# Frontend klasÃ¶rÃ¼ oluÅŸtur
mkdir frontend
cd frontend

# React uygulamasÄ± oluÅŸtur
npx create-react-app . --template typescript

# React Flow'u yÃ¼kle
npm install reactflow
npm install axios
```

### ADIM 10: Frontend - Flow Component

```jsx
// frontend/src/components/Flow.js
import React, { useState, useCallback, useEffect } from 'react';
import ReactFlow, {
  addEdge,
  Background,
  Controls,
  MiniMap,
  useNodesState,
  useEdgesState,
} from 'reactflow';
import 'reactflow/dist/style.css';
import axios from 'axios';

// Custom Node Component
const CustomNode = ({ data }) => {
  return (
    <div style={{
      background: 'white',
      border: '1px solid #ddd',
      borderRadius: '5px',
      padding: '10px',
      minWidth: '150px'
    }}>
      <div style={{ fontWeight: 'bold' }}>{data.label}</div>
      
      {/* Inputs */}
      {data.inputs && data.inputs.map((input, i) => (
        <div key={i} style={{ fontSize: '12px', marginTop: '5px' }}>
          ðŸ“¥ {input.label}
        </div>
      ))}
      
      {/* Outputs */}
      {data.outputs && data.outputs.map((output, i) => (
        <div key={i} style={{ fontSize: '12px', marginTop: '5px' }}>
          ðŸ“¤ {output.label}
        </div>
      ))}
    </div>
  );
};

const nodeTypes = {
  custom: CustomNode,
};

function Flow() {
  const [nodes, setNodes, onNodesChange] = useNodesState([]);
  const [edges, setEdges, onEdgesChange] = useEdgesState([]);
  const [nodeTypes, setNodeTypes] = useState({});

  // Backend'den node tiplerini al
  useEffect(() => {
    axios.get('http://localhost:8000/api/nodes')
      .then(response => {
        setNodeTypes(response.data);
      });
  }, []);

  // Yeni edge ekleme
  const onConnect = useCallback(
    (params) => setEdges((eds) => addEdge(params, eds)),
    [setEdges]
  );

  // Node ekleme (drag & drop)
  const onDrop = useCallback(
    (event) => {
      event.preventDefault();
      
      const type = event.dataTransfer.getData('nodeType');
      const nodeData = nodeTypes[type];
      
      if (!nodeData) return;

      const position = {
        x: event.clientX - event.target.getBoundingClientRect().left,
        y: event.clientY - event.target.getBoundingClientRect().top,
      };

      const newNode = {
        id: `${type}_${Date.now()}`,
        type: 'custom',
        position,
        data: {
          label: nodeData.label,
          nodeType: type,
          inputs: nodeData.inputs,
          outputs: nodeData.outputs,
        },
      };

      setNodes((nds) => nds.concat(newNode));
    },
    [nodeTypes]
  );

  const onDragOver = useCallback((event) => {
    event.preventDefault();
    event.dataTransfer.dropEffect = 'move';
  }, []);

  // Flow'u Ã§alÄ±ÅŸtÄ±r
  const executeFlow = async () => {
    const flowData = {
      nodes: nodes.map(node => ({
        id: node.id,
        type: node.data.nodeType,
        data: node.data
      })),
      edges: edges
    };

    try {
      const response = await axios.post('http://localhost:8000/api/execute', flowData);
      console.log('Result:', response.data);
      alert('Flow executed! Check console for results.');
    } catch (error) {
      console.error('Error:', error);
      alert('Error executing flow!');
    }
  };

  return (
    <div style={{ height: '100vh', display: 'flex' }}>
      {/* Sol Panel - Node Listesi */}
      <div style={{
        width: '200px',
        background: '#f5f5f5',
        padding: '10px',
        borderRight: '1px solid #ddd'
      }}>
        <h3>Nodes</h3>
        {Object.entries(nodeTypes).map(([type, node]) => (
          <div
            key={type}
            draggable
            onDragStart={(e) => e.dataTransfer.setData('nodeType', type)}
            style={{
              background: 'white',
              padding: '10px',
              margin: '5px 0',
              borderRadius: '5px',
              cursor: 'move',
              border: '1px solid #ddd'
            }}
          >
            {node.label}
          </div>
        ))}
        
        <button
          onClick={executeFlow}
          style={{
            marginTop: '20px',
            width: '100%',
            padding: '10px',
            background: '#007bff',
            color: 'white',
            border: 'none',
            borderRadius: '5px',
            cursor: 'pointer'
          }}
        >
          Run Flow
        </button>
      </div>

      {/* SaÄŸ Panel - Flow Editor */}
      <div style={{ flex: 1 }}>
        <ReactFlow
          nodes={nodes}
          edges={edges}
          onNodesChange={onNodesChange}
          onEdgesChange={onEdgesChange}
          onConnect={onConnect}
          onDrop={onDrop}
          onDragOver={onDragOver}
          nodeTypes={nodeTypes}
          fitView
        >
          <Background />
          <Controls />
          <MiniMap />
        </ReactFlow>
      </div>
    </div>
  );
}

export default Flow;
```

### ADIM 11: Basit Bir Flow Ã–rneÄŸi - Chat UygulamasÄ±

```python
# backend/nodes/output_nodes.py
from .base import BaseNode, NodeInput, NodeOutput

class ChatOutputNode(BaseNode):
    """Chat Ã§Ä±ktÄ±sÄ± iÃ§in final node"""
    
    def __init__(self):
        super().__init__()
        self.name = "chat_output"
        self.label = "Chat Output"
        self.category = "outputs"
        
        self.inputs = [
            NodeInput(name="chain", type="object", required=True),
            NodeInput(name="user_input", type="string", required=True)
        ]
        
        self.outputs = [
            NodeOutput(name="response", type="string")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> str:
        """Chain'i Ã§alÄ±ÅŸtÄ±r ve sonucu dÃ¶ndÃ¼r"""
        chain = inputs["chain"]
        user_input = inputs["user_input"]
        
        # LangChain'i Ã§alÄ±ÅŸtÄ±r
        response = await chain.arun(input=user_input)
        
        return response
```

### ADIM 12: Memory (HafÄ±za) Node Ekleyelim

```python
# backend/nodes/memory_nodes.py
from langchain.memory import ConversationBufferMemory
from .base import BaseNode, NodeInput, NodeOutput

class ConversationMemoryNode(BaseNode):
    """Sohbet hafÄ±zasÄ± node'u"""
    
    def __init__(self):
        super().__init__()
        self.name = "conversation_memory"
        self.label = "Conversation Memory"
        self.category = "memory"
        
        self.inputs = [
            NodeInput(name="session_id", type="string", default="default")
        ]
        
        self.outputs = [
            NodeOutput(name="memory", type="ConversationBufferMemory")
        ]
    
    # Global hafÄ±za storage (production'da Redis kullan)
    _memory_store = {}
    
    async def execute(self, inputs: Dict[str, Any]) -> ConversationBufferMemory:
        """Session'a Ã¶zel hafÄ±za dÃ¶ndÃ¼r"""
        session_id = inputs.get("session_id", "default")
        
        # Bu session iÃ§in hafÄ±za var mÄ±?
        if session_id not in self._memory_store:
            self._memory_store[session_id] = ConversationBufferMemory()
        
        return self._memory_store[session_id]
```

### ADIM 13: Tool (AraÃ§) Node'larÄ±

```python
# backend/nodes/tool_nodes.py
from langchain.tools import DuckDuckGoSearchRun
from langchain.tools import Calculator
from .base import BaseNode, NodeOutput

class WebSearchNode(BaseNode):
    """Web arama tool'u"""
    
    def __init__(self):
        super().__init__()
        self.name = "web_search"
        self.label = "Web Search"
        self.category = "tools"
        
        self.outputs = [
            NodeOutput(name="tool", type="Tool")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> DuckDuckGoSearchRun:
        return DuckDuckGoSearchRun()

class CalculatorNode(BaseNode):
    """Hesap makinesi tool'u"""
    
    def __init__(self):
        super().__init__()
        self.name = "calculator"
        self.label = "Calculator"
        self.category = "tools"
        
        self.outputs = [
            NodeOutput(name="tool", type="Tool")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> Calculator:
        return Calculator()
```

### ADIM 14: Agent Node - AkÄ±llÄ± Ajan

```python
# backend/nodes/agent_nodes.py
from langchain.agents import create_react_agent, AgentExecutor
from .base import BaseNode, NodeInput, NodeOutput

class ReactAgentNode(BaseNode):
    """ReAct Agent - DÃ¼ÅŸÃ¼nÃ¼p hareket eden ajan"""
    
    def __init__(self):
        super().__init__()
        self.name = "react_agent"
        self.label = "ReAct Agent"
        self.category = "agents"
        
        self.inputs = [
            NodeInput(name="llm", type="object", required=True),
            NodeInput(name="tools", type="list", required=True),
            NodeInput(name="prompt", type="object", required=True),
            NodeInput(name="memory", type="object", required=False)
        ]
        
        self.outputs = [
            NodeOutput(name="agent", type="AgentExecutor")
        ]
    
    async def execute(self, inputs: Dict[str, Any]) -> AgentExecutor:
        """Agent oluÅŸtur"""
        llm = inputs["llm"]
        tools = inputs["tools"]
        prompt = inputs["prompt"]
        memory = inputs.get("memory")
        
        # Agent oluÅŸtur
        agent = create_react_agent(
            llm=llm,
            tools=tools,
            prompt=prompt
        )
        
        # Executor oluÅŸtur
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            memory=memory,
            verbose=True  # Debug iÃ§in
        )
        
        return agent_executor
```

### ADIM 15: Deployment ve Ã‡alÄ±ÅŸtÄ±rma

```bash
# Backend'i baÅŸlat
cd backend
pip install -r requirements.txt
python main.py

# Frontend'i baÅŸlat (yeni terminal)
cd frontend
npm start
```

### requirements.txt
```
fastapi
uvicorn
langchain
langchain-openai
pydantic
python-multipart
websockets
```

## KULLANIM SENARYOSU

1. **Basit Chat Flow:**
   - ChatGPT Node ekle â†’ API key gir
   - Prompt Template Node ekle â†’ "Sen yardÄ±msever bir asistansÄ±n. {input}"
   - LLM Chain Node ekle
   - BaÄŸlantÄ±larÄ± yap:
     - ChatGPT â†’ LLM Chain (llm giriÅŸine)
     - Prompt â†’ LLM Chain (prompt giriÅŸine)
   - Run Flow!

2. **Agent Flow (AkÄ±llÄ± Asistan):**
   - ChatGPT Node
   - Web Search Tool Node
   - Calculator Tool Node
   - Agent Prompt Node
   - ReAct Agent Node
   - BaÄŸlantÄ±larÄ± yap ve Ã§alÄ±ÅŸtÄ±r!

## Ã–NEMLÄ° NOKTALAR

1. **Her node bir Python class'Ä±** - `execute()` metodu ile Ã§alÄ±ÅŸÄ±r
2. **Node'lar obje dÃ¶ndÃ¼rÃ¼r** - Bu objeler diÄŸer node'lara input olur
3. **Flow executor sÄ±rayÄ± belirler** - Topological sort ile
4. **Registry pattern** - TÃ¼m node'lar merkezi bir yerde kayÄ±tlÄ±
5. **WebSocket** - GerÃ§ek zamanlÄ± chat iÃ§in
6. **Type safety** - Pydantic ile input validation

Bu rehberi takip ederek, Flowise benzeri bir visual LLM orchestration tool'u yapabilirsin!